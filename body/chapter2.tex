\section{相关技术与理论基础}

\subsection{医学图像语义分割基础}

图像分割任务可以分为两个不同的任务类别：语义分割任务和实例分割任务\cite{azad2024}。语义分割是像素级图像分割，图像中的每个像素点都有一个对应的类别，语义分割任务则需要尽量正确预测每个像素点的类别。如图~\ref{fig:seg}所示，实例分割在语义分割任务的基础上，需要将同类别的像素分类为不同的对象实例，即同类不同例。基于医学图像的语义分割任务则是指利用计算机视觉技术去分析和处理2D或3D医学图像，达到将人体器官、软组织和病灶体进行分割、提取，三维重构和展示的目的\cite{liu2021}。

\begin{figure}[htbp]
    \centering
    \subfloat[原图]
    {
        \includegraphics[width=0.3\textwidth]{fig/img_seg.jpg}
    }
    \subfloat[语义分割图]
    {
        \includegraphics[width=0.3\textwidth]{fig/semantic_seg.jpg}
    }
    \subfloat[实例分割图]
    {
        \includegraphics[width=0.3\textwidth]{fig/instance_seg.jpg}
    }
    \caption{语义分割与实例分割对比示意图\cite{kirillov2019}}
    \label{fig:seg}
\end{figure}

\subsubsection{医学图像特点}

如图~\ref{fig:medical_fig} 所示，医学图像包括X射线、超声、MRI等多种成像模态，每种模态具有不同的成像原理和信息特征。同时相较于自然图像，医学图像在图像属性、获取方式与临床语义等方面具有显著差异，形成了若干具有代表性的特征。

\begin{figure}[htbp]
    \centering
    \subfloat[胸部X射线影像]
    {
        \includegraphics[height=4.5cm]{fig/xray_肺.png}
    }
    \hspace{0.7cm}
    \subfloat[乳腺超声影像]
    {
        \includegraphics[height=4.5cm]{fig/乳腺超声图像.png}
    }
    \hspace{0.7cm}
    \subfloat[心脏磁共振成像]
    {
        \includegraphics[height=4.5cm]{fig/心房.png}
    }
    \caption{多模态医学影像示例：X射线、超声与MRI}
    \label{fig:medical_fig}
\end{figure}

接下来将从多模态性、图像质量、结构复杂性等方面对医学图像的主要特点进行系统性概括：

\begin{enumerate}
    \item 多模态性： 
    多模态性是医学图像最本质的特征之一，不同成像技术基于各自的物理机制产生图像，导致图像在分辨率、对比度、噪声特性等方面具有显著差异。例如，CT图像通过X射线衰减反映组织的密度信息，表现为良好的骨骼成像与高密度区域识别能力；MRI通过核磁共振原理获取图像，具有出色的软组织对比度，常用于脑部、脊髓及肿瘤成像。
    
    \item 高噪声和低对比度：
    相较于多数自然图像的高清晰度和高对比度，高噪声与低对比度问题在医学图像中普遍存在。受限于成像设备、器官运动等因素，医学图像常伴有伪影与模糊，如MRI中常见的运动伪影与磁敏感伪影、CT中的金属伪影。低对比度则体现在图像的病灶区域与周围正常组织在灰度分布上高度重叠，如肝脏与肿瘤组织；也常出现多个器官重叠或粘连的情况，如腹部CT图像中的脾脏与左肾的接触区域、脑白质与灰质区域。
    
    \item 解剖结构的拓扑复杂：
    自然图像的物体通常具有清晰空间分层（如“前景-背景”），而在医学图像中器官和组织常呈现多层嵌套（如肠管缠绕、血管穿透脏器）和动态形变（如呼吸导致的肺位移）。同时，自然物体的形状相对稳定，而人体解剖结构会因为个体差异、病理状态产生巨大形态变异，例如前列腺癌患者的腺体体积可膨胀至正常值的3倍。
    
    \item 数据获取和标注困难：
    医学图像的数据获取和标注远高于自然图像。成像成本高、病人隐私问题、罕见病例少等等因素导致医学图像的数据量通常只有数百数千张，甚至更少。同时高质量的可用于图像分割的医学图像需要具有多年经验的临床专家进行逐像素级精细勾画，且不同医生间的标注标准与经验存在差异，导致“标注者间差异”现象普遍存在。
\end{enumerate}

上诉特点使得医学图像相较于自然图像有更高的复杂性，对其的自动分割任务不仅要求模型具备强大的特征表达与结构建模能力，还需应对多种极具挑战性的实际问题。

\subsubsection{医学图像语义分割挑战}

在数据具有多模态性和获取标注困难的情况下，跨模态泛化能力成为了衡量模型在医学图像语义分割性能的关键评估指标，一个鲁棒的能够适用于医学图像语义分割任务的模型应当能够在这种模态一致性不足和低数据量的情况下维持良好稳定的性能。而低对比度和解剖结构复杂的特点，对模型提出了更强的捕捉高分辨率细节并维持边缘清晰度的能力要求，许多早期病灶（如肺部结节、肝癌早期病变）和器官（如视网膜微血管）在图像中的所占面积比例极小，容易在下采样的过程中被忽略和抹除，模型需要能够在这种情况下对小目标进行精细分割。

除了受医学图像固有的复杂性影响，高实时性也是医学图像语义分割模型应当具备的能力，同时也是决定模型能否落地应用的重要门槛。在术中导航、放疗定位、超声实时识别等高时效性场景中，模型不仅要保证分割准确，还需在极短时间内完成推理，这同时也对模型的计算复杂度与硬件适配能力提出了极高的要求。

综上，面向于医学图像的语义分割算法和模型不仅有高分割精度和跨模态泛化的能力要求，还需要面对高实时性等的性能挑战。这种挑战也促使了大量的研究者进入医学图像语义分割领域进行探索，提出了诸多有效的分割算法和创新的网络结构与优化策略，这些工作将在下文中进行全面的介绍。

\subsection{传统分割方法概述}

在相当长的一段时间内，或基于边界或基于区域的传统分割技术作为医学图像分析的基础，提供了一系列复杂性和适用性有所不同的方法。基于区域的分割方法依赖图像的空间特征，例如灰度和纹理，基于边界的分割方法则主要使用梯度信息来确定目标的边界。尽管阈值分割等传统方法在很多场景中有效\cite{xu2024}，但其在跨模态、跨患者等任务中存在很大的局限性（详见第一章1.1节）。

传统分割方法现在来看已经“过时”，但作为深度学习方法兴起前的技术基础，其局限性为引入深度学习提供了动机。因此，本节将聚焦技术原理与医学应用适配性的角度，对阈值分割、边缘检测和聚类分割这三种最具代表性且广泛应用的传统分割方法进行概述总结。

\subsubsection{阈值分割}

阈值分割是图像分割中最基础、最广泛使用的技术之一，其核心思想是通过设定一个或多个灰度阈值，将图像像素进行二分类（如前景和背景）：

\begin{equation}
B(x, y)=\left\{\begin{array}{ll}1, & \text { if } I(x, y) \geq T \\ 0, & \text { if } I(x, y)<T\end{array}\right.
\end{equation}

其中，$I(x, y)$表示图像在坐标$(x, y)$处的像素值，$B(x, y)$表示二值图像在坐标$(x, y)$处的像素值，$T$则是阈值。在图像处理中，阈值分割方法又可以细分为两大类：全局阈值法和局部阈值法。

全局阈值法假设整幅图像的背景与前景有明显的灰度差异，因此通过应用一个统一的阈值$T$来对图像进行分割。比较著名的全局阈值算法包括：Otsu法、迭代法和最小误差法。Otsu法通过最大化类间差异选取最优阈值；迭代法则初始估计一个阈值，然后迭代更新前景和背景的平均灰度值来计算新阈值直至收敛；最小误差法在基于图像前景和背景的像素灰度值呈正态分布的假设前提下，通过计算各分割区域的概率密度函数得到总分类误差并使误差最小化确定阈值。

相对于全局阈值法，局部阈值法假设图像具有不均匀的光照，因此针对每个像素的局部领域单独计算阈值$T$。较为常见的局部阈值算法包括：Niblack算法和Sauvola。Niblack通过计算每个像素上特定窗口内像素值的局部平均值和标准偏差，并利用平均值评估局部亮度、标准偏差衡量对比度和纹理来动态设定阈值：$ T=\mu+k \sigma $。Sauvola则在Niblack的基础上进行改进，将标准偏差的动态范围R引入阈值计算：$ T=\mu\left[1+k\left(\frac{\sigma}{R}-1\right)\right] $，从而更好地处理变化的背景和光照条件。

% 为这一段找一篇参考文献
凭借其计算简单、易于实现等优点，阈值法在灰度分布清晰、对比度明显的医学场景中广泛应用，如X射线骨骼分割、肺部CT气腔提取等初步分割任务。但是由于依赖图像整体灰度分布，在面对光照不均、伪影干扰、组织边界模糊以及病灶与背景对比度微弱等复杂医学图像时，阈值法往往出现误分割、边界锯齿或目标遗漏等问题。此外，阈值法也难以处理多目标或多组织分割任务，需要手动调节多个阈值，增加了流程复杂度。

\subsubsection{边缘检测}

% 记得插入参考文献

边缘是指两个均匀区域之间的边界，表现为图像中像素强度的局部突变，而边缘检测的核心就在于识别定位图像中像素强度突变的位置。

图像边缘具有两个基本特性：方向与幅值。沿着边缘方向，像素值的变化往往较为平缓；而在垂直于边缘方向，像素值的变化则较为剧烈。基于这一特性，通过应用一阶和二阶微分算子与图像像素值矩阵进行卷积运算，精确计算各像素点的梯度变化或曲率，从而实现提取边缘特性。

常见的一阶微分算子包括Roberts交叉算子、Prewitt算子、Sobel算子以及Canny边缘检测器。Prewitt算子与Sobel算子均采用像素邻域差分法进行边缘检测。其中，Prewitt算子对边缘方向具有更高的敏感性，而Sobel算子则通过改进的噪声抑制能力获得更优性能，但代价是可能导致边缘轻微模糊。Canny算子作为多阶段边缘检测算法的典型代表，以高精度著称，不仅能有效抑制噪声干扰，还可实现边缘的准确定位，但其计算复杂度显著高于其他算子。

二阶微分算子如Laplacian算子和LoG算子同样被广泛采用。基于二阶导数的Laplacian算子对图像细节具有突出增强作用。尽管该算子易受噪声影响，但在细微特征增强方面表现卓越。LoG算子通过高斯平滑预处理与Laplacian算子的协同作用，有效降低了噪声干扰，特别适用于噪声敏感环境下需要精确定位边缘的应用场景。

% 插入参考文献
如表~\ref{tab:edge_detectors}所示，传统边缘检测算子因其算法特性各异而展现出不同优缺点，因此也具有不同的应用价值和局限性，适用于不同的应用场景。Roberts算子凭借其计算效率高的优势，适用于病理切片等显微图像的快速分析，但对噪声敏感的特性使其在CT/MRI等模态中易产生伪边缘。Prewitt算子和Sobel算子因其通过加权增强边缘方向性，故适用于如X光胸片肋骨等轮廓清晰的图像分割，但难以处理边界模糊的情况；Canny算子则因其具备噪声抑制、边缘连接性强等特性，能精确定位MRI脑肿瘤边界，却存在参数调优复杂、计算耗时等问题。Laplacian算子对微小钙化点检测敏感，却完全无法抵抗超声斑点噪声的干扰。LoG算子虽能实现多模态边缘增强，但其高昂的计算成本限制了临床应用。

\renewcommand{\tabularxcolumn}[1]{m{#1}}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\begin{table}[!htbp]
\centering
\caption{不同边缘检测算子的优缺点比较}
\label{tab:edge_detectors}
\begin{tabularx}{\textwidth}{@{}C C C@{}}
\toprule
\textbf{算子} & \textbf{优点} & \textbf{缺点} \\
\midrule
Roberts & 计算简单 & 对噪声敏感，边缘定位不准 \\
\addlinespace
Prewitt & 对边缘方向敏感 & 对噪声敏感，边缘较模糊 \\
\addlinespace
Sobel & 抑制噪声 & 边缘易过平滑\\
\addlinespace
Canny & 边缘检测精度高，抗噪性强 & 计算复杂，依赖参数调优\\
\addlinespace
Laplacian & 能定位边缘中心 & 抗噪性极差，无方向信息 \\
\addlinespace
LoG算子 & 抗噪性强且边缘定位准 & 计算量大，可能丢失细边缘 \\
\bottomrule
\end{tabularx}
\end{table}

\subsubsection{聚类分割}

聚类分割通过将相似特征的像素归类至同一簇实现图像分割，其核心在于定义合理的相似性度量。根据聚类策略的不同，主要分为层次聚类与划分式聚类两类。

在层次聚类方法中，簇的生成通常通过一种迭代式的模式划分过程实现，该过程可以采用自顶向下或自底向上的策略，通过构建树状图生成每个簇仅包含单一数据实体的层级簇结构来完成聚类任务。尽管层次聚类方法具有良好的可解释性与层级结构建模能力，但在医学图像语义分割场景下存在若干显著缺陷：

\begin{enumerate}
    \item 贪心策略限制：样本一旦归类无法修正，噪声或离群点易导致错误累积。
    \item 计算复杂度高：时间复杂度达$O(n^3)$，难以处理大规模医学数据（如全脑MRI体素）。
    \item 预设参数敏感：需人工设定簇数或终止条件，难以自适应复杂解剖结构（如肿瘤浸润区域）。
\end{enumerate}

划分式聚类方法（如k-means算法、模糊c均值算法）则通过优化目标函数，将数据样本划分为若干个彼此独立的簇，从而增强簇内样本间的相似性，并尽可能降低簇间差异，从而寻求最优的聚类配置。其主要优势在于其具备迭代优化能力，能有效适应数据结构的变化。但其局限性也同样突出：

\begin{enumerate}
    \item 初始条件敏感：随机初始簇中心可能导致结果不稳定。
    \item 形状假设偏差：默认球形簇分布，难以分割非凸结构（如树枝状血管网络）。
    \item 噪声干扰：离群点易扭曲簇中心（如超声图像中的斑点噪声）。
\end{enumerate}

\subsection{基于深度学习的语义分割技术}

深度学习作为机器学习与人工智能领域的重要研究方向，其核心在于通过深度神经网络模拟人脑学习机制，从海量数据（语音、文本、图像等）中以无监督方式自动提取特征表征。神经网络通过大量互连的神经元，从结构、实现机理和功能上模拟人脑神经网络，每个神经元可视为基础信息处理单元，通过层级化连接形成完整的网络架构\cite{qiu2020nndl}。该架构的出现使得端到端图像处理成为可能，当网络隐层扩展至多层结构时即形成深度学习范式。在计算机视觉领域，深度学习已成功应用于数据降维、手写体识别、模式识别等方向，尤其在图像识别、图像修复、图像分割、目标追踪及场景解析等任务中展现出卓越性能。

\subsubsection{卷积神经网络}

% 章节脉络：
% 介绍卷积神经网络 -> 介绍FCN模型 -> FCN的成功和局限
% 1.介绍卷积神经网络：历史及基本介绍 -> 技术细节 -> CNN如何正式引入图像分割领域
% 2.介绍FCN模型： 模型架构 -> 如何完成语义分割
% 3.成功和局限： 成功在哪 -> 局限在哪

% 1.1
卷积神经网络是深度学习与图像处理技术相结合的经典网络结构，作为深度学习技术领域最具代表性的神经网络之一，在图像分析与处理领域取得了诸多突破性进展。例如，在学术界广泛使用的标准图像标注集ImageNet上，基于卷积神经网络的特征提取与分类、模式识别等研究成果颇为丰硕。

受生物学上Hubel等人\cite{hubel1962}提出的感受野的概念启发，1980年Fukushima\cite{fukushima1980}提出了神经认知机，被视为卷积神经网络的首次实现网络。与全连接层前馈网络不同的是，卷积神经网络通过交叉堆叠卷积层、池化层和全连接层形成前馈神经网络。大量的卷积层和池化层使得网络可以共享前层网络不同位置的特征映射权重，并利用空间相对关系来大大减少网络的参数量，这与大脑视觉神经元只能对视网膜上某一特定区域的光刺激产生反应的机制类似。同时，结构特性带来的一定程度上的平移、缩放和旋转不变性，使得卷积神经网络在图像和视频分析任务上具有远超其他神经网络模型的准确率。

% 1.2
图~\ref{fig:cnn}展示了一般卷积网络的整体结构，其中包含若干个卷积核和非线性激活函数的卷积层是卷积神经网络的核心组成部分。所有卷积核对输入数据进行并行卷积运算得到卷积线性输出，之后再经过激活函数就得到了卷积层的输出\cite{Goodfellow-et-al-2016}。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{fig/cnn_frame.png}
    \caption{卷积网络的整体结构}
    \label{fig:cnn}
\end{figure}

在图像处理中最常见的卷积运算是二维卷积运算，即输入数据是二维张量：

\begin{equation}
    O(i, j)=(I * K)(i, j)=\sum_{m} \sum_{n} I(m, n) K(i-m, j-n)
\end{equation}

其中$*$表示二维卷积运算，图~\ref{fig:2dcnn}展示了其计算过程。$I$和$K$都是二维张量，$ K \in \mathbb{R}$表示可学习的二维卷积核权重向量，$I \in \mathbb{R}$表示输入的二维图像数据，$(x, y)$代表像素点坐标，$(m, n)$代表输入图像的尺寸。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{fig/2dcnn-1.png}
    \caption{二维卷积运算}
    \label{fig:2dcnn}
\end{figure}

% 2.1
在全卷积网络（Fully Convolution Network， FCN）出现之前，诸如GoogLeNet、ResNet等采用卷积神经网络构建的模型主要应用于图像分类和识别，在图像语义分割领域缺乏有针对性的、表现优异的卷积神经网络模型，而FCN是首个开创性将卷积神经网络引入图像语义分割领域的网络模型\cite{shelhamer2016}。

如图~\ref{fig:fcn_frame}所示，作为后续诸多分割模型模型的基础架构，FCN借鉴了VGG网络的层次化设计，可以支持任意尺寸的输入图像，采用逐像素交叉熵损失进行反向传播，整个网络端到端训练输出与输入同尺寸的逐像素类别图。

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\textwidth]{fig/fcn_frame.png}
    \caption{全卷积网络模型架构}
    \label{fig:fcn_frame}
\end{figure}

% 2.2
与传统分割模型和卷积神经网络通过若干个全连接层得到一个全局类别标签不同的是，FCN中的全连接层被全部替换为了卷积层，输入图像首先经过卷积层提取特征和上下文信息；之后经过反卷积层逐步从低分率特征图恢复到原分辨率图像。其中，卷积层、反卷积层也称为编码器、解码器，这样的网络结构也称为编码器-解码器结构。

% 3.1 + 3.2
FCN模型是语义分割领域的里程碑并开启了“全卷积”时代，后续的SegNet、Deeplab和U-Net等模型皆在此框架上演进。全卷积的架构不仅解决了全连接层会破坏空间信息导致模型整体性能下降的问题，还打破了输入尺寸的限制，使大面积图像一次向前即可完成推理。然而，如图~\ref{fig:fcn_pre}所示，由于过深的卷积下采样，这使得FCN网络的分割结果存在边界粗糙、细节丢失等问题，虽然Long等人尝试通过跳跃连接的方式，将卷积层下采样的结果与上采样的结果进行特征融合以缓解问题，但对于医学图像语义分割这种图像包含小器官小目标且高精度分割要求的任务，FCN网络的分割结果还远远无法满足要求。

\begin{figure}[htbp]
    \centering
    \subfloat[原图]
    {
        \includegraphics[width=0.25\textwidth]{fig/img4.png}
    }
    \subfloat[原图分割图]
    {
        \includegraphics[width=0.25\textwidth]{fig/gt4.png}
    }
    \subfloat[FCN预测分割图]
    {
        \includegraphics[width=0.25\textwidth]{fig/predsf4.png}
    }
    \caption{原图分割图与FCN预测分割图的差别\cite{shelhamer2016}}
    \label{fig:fcn_pre}
\end{figure}

\subsubsection{U-Net网络}
% 章节脉络：模型架构 -> 模型医学图像优势 -> 模型存在的局限性
% 模型架构：整体架构 -> 各部分架构及其左右
% 模型优势：为什么如此有效 -> 在医学图像语义分割领域取得的具体成果
% 局限性： 模型局限 -> 实践局限

% 1.1
受FCN网络的启发，Ronneberger等人在其全卷积架构和解码器-编码器网络结构设计的基础上提出了U-Net网络，这个专门解决为医学图像语义分割任务而出现的模型在出现后广泛被应用于医学图像语义分割，也成为了后续在此基础上进行改进的U-Net变体模型的基线模型。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{fig/u-net-architecture.png}
    \caption{U-Net网络架构\cite{ronneberger2015}}
    \label{fig:unet_frame}
\end{figure}

图~\ref{fig:unet_frame}展示了U-Net网络的网络架构，由两部分构成：

\begin{enumerate}
    \item 收缩路径：也称下采样路径。由多个卷积层和池化层组成一个下采样模块，用于提取语义与上下文特征。
    \item 扩张路径：也称上采样路径。由转置卷积层和多个卷积层组成一个上采样模块，用于逐步恢复特征图的空间分辨率。
\end{enumerate}

% 1.2
可以看出，U-Net网络结构与FCN相似，均采用了编码器和编码器以及跳跃连接的拓扑结构。有所区别的是，FCN缺少严格配对的收缩路径和扩张路径，仅在三个尺度上将早期特征“逐像素相加。U-Net在这个基础上构建了与收缩路径一一对应的扩张路径，形成了经典的对称“U”字结构。每个编码器和解码器相对应的层都进行输出拼接，再经过两个卷积层卷积对拼接特征图进行特征融合。

这种创新式的跳跃连接方式，将收缩路径上高分辨率的上下文信息传递到深层网络，使得模型能够复用低层细节特征和高层语义信息，从而实现对目标的精准定位。同时，每次上采样后都采用3×3卷积连续细化的方式，使得像素级定位更加准确，特别适合需要像素分割精度的医学图像语义分割任务。凭借着U-Net模型，Ronneberger等人在ISBI细胞跟踪竞赛中以远超其他模型的性能表现大获成功\cite{ronneberger2015}。