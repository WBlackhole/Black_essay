\section{相关技术与理论基础}

\subsection{医学图像语义分割基础}

图像分割任务有两个不同的任务类别：语义分割任务和实例分割任务\cite{azad2024}。语义分割是像素级图像分割，图像中的每个像素点都会有一个对应的类别，而语义分割任务则需要尽量正确预测每个像素点的类别。实例分割需要在语义分割的基础上，将同类别的像素分类为不同的对象实例。基于医学图像的语义分割任务则是指利用计算机视觉技术去分析和处理2D或3D医学图像，达到将人体器官、软组织和病灶体进行分割、提取，三维重构和展示的目的\cite{liu2021}。

% 附图：语义分割和实例分割

\subsubsection{医学图像特点与语义分割挑战}

% 考虑是否引用第一章某处内容
医学图像作为临床诊断与治疗决策的重要依据，具备区别于自然图像的一系列独特特点：

\begin{enumerate}
    \item 多模态性： 
    多模态性是医学图像最本质的特征之一，不同成像技术基于各自的物理机制产生图像，导致图像在分辨率、对比度、噪声特性等方面具有显著差异。例如，CT图像通过X射线衰减反映组织的密度信息，表现为良好的骨骼成像与高密度区域识别能力；MRI通过核磁共振原理获取图像，具有出色的软组织对比度，常用于脑部、脊髓及肿瘤成像。
    
    \item 高噪声和低对比度：
    相较于多数自然图像的高清晰度和高对比度，高噪声与低对比度问题在医学图像中普遍存在。受限于成像设备、器官运动等因素，医学图像常伴有伪影与模糊，如MRI中常见的运动伪影与磁敏感伪影、CT中的金属伪影。低对比度则体现在图像的病灶区域与周围正常组织在灰度分布上高度重叠，如肝脏与肿瘤组织；也常出现多个器官重叠或粘连的情况，如腹部CT图像中的脾脏与左肾的接触区域、脑白质与灰质区域。
    
    \item 解剖结构的拓扑复杂：
    自然图像的物体通常具有清晰空间分层（如“前景-背景”），而在医学图像中器官和组织常呈现多层嵌套（如肠管缠绕、血管穿透脏器）和动态形变（如呼吸导致的肺位移）。同时，自然物体的形状相对稳定，而人体解剖结构会因为个体差异、病理状态产生巨大形态变异，例如前列腺癌患者的腺体体积可膨胀至正常值的3倍。
    
    \item 数据获取和标注困难：
    医学图像的数据获取和标注远高于自然图像。成像成本高、病人隐私问题、罕见病例少等等因素导致医学图像的数据量通常只有数百数千张，甚至更少。同时高质量的可用于图像分割的医学图像需要具有多年经验的临床专家进行逐像素级精细勾画，且不同医生间的标注标准与经验存在差异，导致“标注者间差异”现象普遍存在。

\end{enumerate}

% 附图：自然图像+高噪声医学图像+复杂拓扑结构医学图像

上诉特点使得医学图像相较于自然图像有更高的复杂性，对其的自动分割任务不仅要求模型具备强大的特征表达与结构建模能力，还需应对多种极具挑战性的实际问题。

在多模态性和数据获取标注困难的特点影响下，跨模态泛化能力成为了衡量模型在医学图像语义分割性能的关键评估指标，一个鲁棒的能够适用于医学图像语义分割任务的模型应当能够在这种模态一致性不足和低数据量的情况下维持良好稳定的性能。而由于低对比度和解剖结构复杂的特点则对模型提出了更强的捕捉高分辨率细节并维持边缘清晰度的能力，许多早期病灶（如肺部结节、肝癌早期病变）和器官（如视网膜微血管）在图像中的所占面积比例极小，容易在下采样的过程中被忽略和抹除，模型需要能够在这种情况下对小目标进行精细分割。

除了受医学图像固有的复杂性影响，高实时性也是医学图像语义分割模型应当具备的能力，也是决定其能否落地应用的重要门槛。在术中导航、放疗定位、超声实时识别等高时效性场景中，模型不仅要保证分割准确，还需在极短时间内完成推理，这同时也对模型的计算复杂度与硬件适配能力提出了极高的要求。综上，面向于医学图像的语义分割算法和模型面临着高分割精度、跨模态泛化和高实时性等等能力要求和挑战。但与此同时，这也促使了大量的研究者进入该领域进行探索，提出了诸多有效的分割算法和创新的网络结构与优化策略。

\subsection{传统分割方法概述}

在相当长的一段时间内，传统分割技术作为医学图像分析的基础提供了一系列复杂性和适用性有所不同的方法，包括阈值分割、边缘检测、区域生长及聚类分割等在内的传统分割方法在很多场合下已被证明有效\cite{xu2024}。接下来的内容将对阈值分割、边缘检测和聚类分割这三种最具代表性且广泛应用的传统分割方法进行概述总结。

\subsubsection{阈值分割}

阈值分割是图像分割中最基础、最广泛使用的技术之一，其核心思想是通过设定一个或多个灰度阈值，将图像像素进行二分类（如前景和背景）：

\[
B(x, y)=\left\{\begin{array}{ll}1, & \text { if } I(x, y) \geq T \\ 0, & \text { if } I(x, y)<T\end{array}\right.
\]

其中，$I(x, y)$表示图像在坐标$(x, y)$处的像素值，$B(x, y)$表示二元图像在坐标$(x, y)$处的像素值，$T$则是阈值。在图像处理中，阈值分割方法又可以细分为两大类：全局阈值法和局部阈值法。

全局阈值法假设整幅图像的背景与前景有明显的灰度差异，因此通过应用一个统一的阈值$T$来对图像进行分割。比较著名的全局阈值算法包括：Otsu法、迭代法和最小误差法。Otsu法通过最大化类间差异选取最优阈值；迭代法则初始估计一个阈值，然后迭代更新前景和背景的平均灰度值来计算新阈值直至收敛；最小误差法在基于图像前景和背景的像素灰度值呈正态分布的假设前提下，通过计算各分割区域的概率密度函数得到总分类误差并使误差最小化确定阈值。全局阈值法在图像灰度分布较均匀、对比度明显时表现良好，且计算成本低易于实现和集成到实时系统。但是，该方法在光照不均或对比度不明显的情况下分割效果差，同时也不适用于复杂背景或多目标图像分割。

相对于全局阈值法，局部阈值法假设图像具有不均匀的光照，因此针对每个像素的局部领域单独计算阈值$T$。较为常见的局部阈值算法包括：Niblack算法和Sauvola。Niblack通过计算每个像素上特定窗口内像素值的局部平均值和标准偏差，并利用平均值评估局部亮度、标准偏差衡量对比度和纹理来动态设定阈值：$ T=\mu+k \sigma $。Sauvola则在Niblack的基础上进行改进，将标准偏差的动态范围R引入阈值计算：$ T=\mu\left[1+k\left(\frac{\sigma}{R}-1\right)\right] $，从而更好地处理变化的背景和光照条件。局部处理使得局部阈值法能处理光照不均、阴影遮挡的情况，提高了图像细节的保留能力，使其能适用于安全监控、指纹识别等对细节要求较高的场景。但是同时，其计算复杂度也变得更高、运行时间较长，而且在噪声较大的区域容易误判。

\subsubsection{边缘检测}

\subsubsection{聚类分割}

\subsection{深度学习与语义分割技术}

\subsubsection{卷积神经网络}

\subsubsection{U-Net网络}


\subsection{模型评估指标}